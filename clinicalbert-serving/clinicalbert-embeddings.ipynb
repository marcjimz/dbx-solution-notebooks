{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "669346da-fb1b-4b56-a9ad-24b892de6365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers mlflow torch mlflow[databricks]\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a93a216-64df-45be-8eeb-a9c1f6792189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e063827-8ed1-4e5e-a097-f983d2a0f621",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0d56056-cc4c-4241-871e-7251410ee81d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_catalog = \"marcin_demo\"\n",
    "uc_schema = \"default\"\n",
    "uc_model_name = \"clinicalbert_embeddings\"\n",
    "registered_model_name = f\"{uc_catalog}.{uc_schema}.{uc_model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ac3c61-5363-485c-a51f-cef4fce5879b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load ClinicalBERT model and tokenizer\n",
    "model_name = \"medicalai/ClinicalBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded {model_name}\")\n",
    "print(f\"Model hidden size (embedding dimensions): {model.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab890a2a-a244-4688-9029-aa6df9264a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract embeddings using CLS token approach\n",
    "# Pretty good research paper: https://www.researchgate.net/publication/332342631_ClinicalBERT_Modeling_Clinical_Notes_and_Predicting_Hospital_Readmission\n",
    "def extract_embeddings(texts):\n",
    "    \"\"\"\n",
    "    Extract embeddings from ClinicalBERT model using CLS token.\n",
    "    \n",
    "    Args:\n",
    "        texts: List of strings or single string\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of shape [batch_size, 768] containing embeddings\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    # Tokenize input texts\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract CLS token embeddings\n",
    "    cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return cls_embeddings\n",
    "\n",
    "# Test with a simple clinical text\n",
    "test_text = \"The patient was diagnosed with type 2 diabetes and prescribed medication.\"\n",
    "test_embedding = extract_embeddings(test_text)\n",
    "\n",
    "print(f\"Test embedding shape: {test_embedding.shape}\")\n",
    "print(f\"Embedding dimensions: {test_embedding.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0441ed64-a356-43f1-816c-875af503113c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ICD10 code examples with descriptions\n",
    "icd10_examples = [\n",
    "    \"ICD10: E11.9 - Type 2 diabetes mellitus without complications\",\n",
    "    \"ICD10: I10 - Essential (primary) hypertension\",\n",
    "    \"ICD10: J44.1 - Chronic obstructive pulmonary disease with (acute) exacerbation\",\n",
    "]\n",
    "\n",
    "# Generate embeddings for ICD10 codes\n",
    "icd10_embeddings = extract_embeddings(icd10_examples)\n",
    "\n",
    "print(f\"Generated embeddings for {len(icd10_examples)} ICD10 codes\")\n",
    "print(f\"Embeddings shape: {icd10_embeddings.shape}\")\n",
    "print(f\"Embedding dimensions: {icd10_embeddings.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ICD10 Code Examples and Their Embeddings:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (text, embedding) in enumerate(zip(icd10_examples, icd10_embeddings)):\n",
    "    print(f\"\\n{i+1}. {text}\")\n",
    "    print(f\"   Embedding shape: {embedding.shape}\")\n",
    "    print(f\"   Stats - Mean: {embedding.mean():.4f}, Std: {embedding.std():.4f}, Min: {embedding.min():.4f}, Max: {embedding.max():.4f}\")\n",
    "    print(f\"   First 10 values: {embedding[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb10a9e-300a-4585-a71c-ff27676ba7f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define custom MLflow PyFunc model for ClinicalBERT embeddings\n",
    "class ClinicalBERTEmbeddings(mlflow.pyfunc.PythonModel):\n",
    "    \"\"\"\n",
    "    Custom PyFunc wrapper for ClinicalBERT embedding extraction.\n",
    "    Compatible with Databricks Model Serving.\n",
    "    \"\"\"\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        \"\"\"Load model and tokenizer from artifacts when serving endpoint initializes\"\"\"\n",
    "        import torch\n",
    "        from transformers import AutoModel, AutoTokenizer\n",
    "        \n",
    "        model_path = context.artifacts[\"model_path\"]\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict(self, context, model_input):\n",
    "        \"\"\"\n",
    "        Extract embeddings from input texts.\n",
    "        \n",
    "        Args:\n",
    "            context: MLflow context\n",
    "            model_input: pandas DataFrame or list of strings\n",
    "        \n",
    "        Returns:\n",
    "            numpy array of shape [batch_size, 768] containing embeddings\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Handle different input formats\n",
    "        if isinstance(model_input, pd.DataFrame):\n",
    "            texts = model_input.iloc[:, 0].tolist()\n",
    "        elif isinstance(model_input, list):\n",
    "            texts = model_input\n",
    "        else:\n",
    "            texts = [str(model_input)]\n",
    "        \n",
    "        # Tokenize inputs\n",
    "        inputs = self.tokenizer(\n",
    "            texts, \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=512, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Generate embeddings\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        \n",
    "        # Extract CLS token embeddings\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        \n",
    "        return cls_embeddings\n",
    "\n",
    "print(\"ClinicalBERTEmbeddings PyFunc model defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567b89b6-2230-4d4a-876c-d8fb781282fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare input example and signature for MLflow\n",
    "input_example = icd10_examples[:3]\n",
    "sample_output = extract_embeddings(input_example)\n",
    "\n",
    "signature = mlflow.models.infer_signature(input_example, sample_output)\n",
    "\n",
    "print(\"MLflow Model Signature:\")\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2fc0d85-9d1f-4801-83a4-012d2f472a30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Save model and tokenizer to temporary directory for MLflow artifact logging\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    model_save_path = os.path.join(tmp_dir, \"clinicalbert\")\n",
    "    \n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    \n",
    "    # Log model with MLflow\n",
    "    with mlflow.start_run() as run:\n",
    "        model_info = mlflow.pyfunc.log_model(\n",
    "            artifact_path=\"clinicalbert_embeddings\",\n",
    "            python_model=ClinicalBERTEmbeddings(),\n",
    "            artifacts={\"model_path\": model_save_path},\n",
    "            input_example=input_example,\n",
    "            signature=signature,\n",
    "            registered_model_name=registered_model_name,\n",
    "            pip_requirements=[\n",
    "                \"transformers\",\n",
    "                \"torch\",\n",
    "                \"numpy\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "model_uri = model_info.model_uri\n",
    "registered_model_version = model_info.registered_model_version\n",
    "\n",
    "print(f\"Model URI: {model_uri}\")\n",
    "print(f\"Registered Model Version: {registered_model_version}\")\n",
    "print(f\"Model registered in Unity Catalog as: {registered_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4e79f39-2bc9-4cad-83c3-ac4d32d85657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "# Validate the serving payload\n",
    "serving_payload = \"\"\"{\n",
    "  \"inputs\": [\n",
    "    \"ICD10: E11.9 - Type 2 diabetes mellitus without complications\",\n",
    "    \"ICD10: I10 - Essential (primary) hypertension\"\n",
    "  ]\n",
    "}\"\"\"\n",
    "\n",
    "validation_result = validate_serving_input(model_uri, serving_payload)\n",
    "print(\"Serving payload validation successful\")\n",
    "print(validation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baab8617-8afa-4e65-bdc1-7b40b72940f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load and test the model from Unity Catalog\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"models:/{registered_model_name}/{registered_model_version}\")\n",
    "\n",
    "# Test with ICD10 code examples\n",
    "test_icd10_codes = [\n",
    "    \"ICD10: E11.9 - Type 2 diabetes mellitus without complications\",\n",
    "    \"ICD10: I10 - Essential (primary) hypertension\",\n",
    "    \"ICD10: J44.1 - Chronic obstructive pulmonary disease with (acute) exacerbation\",\n",
    "    \"ICD10: I50.9 - Heart failure, unspecified\",\n",
    "    \"ICD10: N18.3 - Chronic kidney disease, stage 3 (moderate)\"\n",
    "]\n",
    "\n",
    "embeddings = loaded_model.predict(test_icd10_codes)\n",
    "\n",
    "print(f\"Generated embeddings for {len(test_icd10_codes)} ICD10 codes\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embedding dimensions: {embeddings.shape[1]}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ICD10 Code Embeddings from Unity Catalog Model:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (code, embedding) in enumerate(zip(test_icd10_codes, embeddings)):\n",
    "    print(f\"\\n{i+1}. {code}\")\n",
    "    print(f\"   Shape: {embedding.shape}\")\n",
    "    print(f\"   Stats - Mean: {embedding.mean():.4f}, Std: {embedding.std():.4f}\")\n",
    "    print(f\"   Range: [{embedding.min():.4f}, {embedding.max():.4f}]\")\n",
    "    print(f\"   First 5 values: {embedding[:5]}\")\n",
    "\n",
    "# # Display embeddings as DataFrame\n",
    "# embeddings_df = pd.DataFrame(\n",
    "#     embeddings,\n",
    "#     index=[f\"ICD10_{i+1}\" for i in range(len(test_icd10_codes))]\n",
    "# )\n",
    "# print(f\"\\nEmbeddings DataFrame shape: {embeddings_df.shape}\")\n",
    "# embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b08fba-1e6c-4308-8b6d-e2fd933bf20e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# # Create a deployment client\n",
    "# client = get_deploy_client(\"databricks\")\n",
    "# endpoint_name = \"clinicalbert_embeddings_endpoint\"\n",
    "\n",
    "# endpoint = client.create_endpoint(\n",
    "#     name=endpoint_name,\n",
    "#     config={\n",
    "#         \"served_entities\": [\n",
    "#             {\n",
    "#                 \"entity_name\": f\"{registered_model_name}\",\n",
    "#                 \"entity_version\": f\"{registered_model_version}\",\n",
    "#                 \"workload_size\": \"Small\",\n",
    "#                 \"scale_to_zero_enabled\": True\n",
    "#             }\n",
    "#         ],\n",
    "#         \"traffic_config\": {\n",
    "#             \"routes\": [\n",
    "#                 {\n",
    "#                     \"served_model_name\": f\"{uc_model_name}-{registered_model_version}\",\n",
    "#                     \"traffic_percentage\": 100\n",
    "#                 }\n",
    "#             ]\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# print(f\"Endpoint {endpoint_name} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c59833d-4a15-4641-8466-c906f878bbd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# # Wait for endpoint to be ready\n",
    "# def wait_for_endpoint_ready(client, endpoint_name, timeout=1200, interval=60):\n",
    "#     start_time = time.time()\n",
    "#     while time.time() - start_time < timeout:\n",
    "#         endpoint_info = client.get_endpoint(endpoint_name)\n",
    "#         endpoint_state = endpoint_info.get('state', 'UNKNOWN')['ready']\n",
    "#         if endpoint_state == 'READY':\n",
    "#             print(f\"Endpoint {endpoint_name} is ready.\")\n",
    "#             return\n",
    "#         elif endpoint_state == 'FAILED':\n",
    "#             raise Exception(f\"Endpoint {endpoint_name} creation failed.\")\n",
    "#         else:\n",
    "#             print(f\"Endpoint {endpoint_name} is in state {endpoint_state}. Waiting...\")\n",
    "#             time.sleep(interval)\n",
    "#     raise TimeoutError(f\"Timeout while waiting for endpoint {endpoint_name} to be ready.\")\n",
    "\n",
    "# wait_for_endpoint_ready(client, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "703f7da1-db1f-4906-8918-06a7c821a867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Test the serving endpoint\n",
    "# response = client.predict(\n",
    "#     endpoint=endpoint_name,\n",
    "#     inputs={\"inputs\": [\n",
    "#         \"ICD10: E11.9 - Type 2 diabetes mellitus without complications\",\n",
    "#         \"ICD10: I10 - Essential (primary) hypertension\",\n",
    "#         \"ICD10: J44.1 - Chronic obstructive pulmonary disease with (acute) exacerbation\",\n",
    "#         \"ICD10: I50.9 - Heart failure, unspecified\",\n",
    "#         \"ICD10: N18.3 - Chronic kidney disease, stage 3 (moderate)\",\n",
    "#         \"ICD10: J45.909 - Unspecified asthma, uncomplicated\",\n",
    "#         \"ICD10: I21.9 - Acute myocardial infarction, unspecified\"\n",
    "#     ]}\n",
    "# )\n",
    "\n",
    "# # Process endpoint response\n",
    "# embeddings_from_endpoint = np.array(response['predictions'])\n",
    "\n",
    "# print(f\"Received embeddings from serving endpoint\")\n",
    "# print(f\"Embeddings shape: {embeddings_from_endpoint.shape}\")\n",
    "# print(f\"Embedding dimensions: {embeddings_from_endpoint.shape[1]}\")\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"Serving Endpoint Response - ICD10 Embeddings:\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# for i, embedding in enumerate(embeddings_from_endpoint):\n",
    "#     print(f\"\\nICD10 Code {i+1}:\")\n",
    "#     print(f\"   Embedding shape: {embedding.shape}\")\n",
    "#     print(f\"   Stats - Mean: {embedding.mean():.4f}, Std: {embedding.std():.4f}\")\n",
    "#     print(f\"   Range: [{embedding.min():.4f}, {embedding.max():.4f}]\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "clinicalbert-embeddings",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
