{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef5e74c2-23a3-4994-8aa3-843d675c4bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simple Column Access Audit\n",
    "\n",
    "This notebook demonstrates the key linkage between `system.query.history` and `system.access.column_lineage` using the `statement_id` field.\n",
    "\n",
    "**Important**: Column names may vary at time of execution; run DESCRIBE commands first to see available columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c03cb5f7-3519-4f5d-8e7c-5f4679acb4c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog.Schema: marcin_demo.demo_schema_v2\nUser: marcin.jimenez@databricks.com\nTime Range: Last 24 hours\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "\n",
    "# Configuration\n",
    "TARGET_CATALOG = \"marcin_demo\"  # CHANGE THIS\n",
    "TARGET_SCHEMA = \"demo_schema_v2\"    # CHANGE THIS\n",
    "\n",
    "# Time range and current user\n",
    "END_TIME = datetime.now(pytz.UTC) + timedelta(minutes=5) #fast-forward for example\n",
    "START_TIME = END_TIME - timedelta(days=1)\n",
    "CURRENT_USER = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "\n",
    "print(f\"Catalog.Schema: {TARGET_CATALOG}.{TARGET_SCHEMA}\")\n",
    "print(f\"User: {CURRENT_USER}\")\n",
    "print(f\"Time Range: Last 24 hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b7f373-9519-4c06-9e31-cd28b3805e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG marcin_demo;\n",
    "CREATE SCHEMA IF NOT EXISTS demo_schema_v2;\n",
    "USE marcin_demo.demo_schema_v2;\n",
    "DROP TABLE IF EXISTS sample_iris_v2;\n",
    "\n",
    "-- 1) Create the table from the CSV in DBFS\n",
    "CREATE TABLE IF NOT EXISTS sample_iris_v2 (\n",
    "  sepal_length DOUBLE,\n",
    "  sepal_width  DOUBLE,\n",
    "  petal_length DOUBLE,\n",
    "  petal_width  DOUBLE,\n",
    "  species      STRING\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "-- -- 2) Tag the sensitive columns\n",
    "SET TAG ON COLUMN sample_iris_v2.petal_width SENSITIVE;\n",
    "SET TAG ON COLUMN sample_iris_v2.species SENSITIVE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8249ad3-8704-445f-9379-30306787e44e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/pyspark/pandas/utils.py:1026: PandasAPIOnSparkAdviceWarning: The config 'spark.sql.ansi.enabled' is set to True. This can cause unexpected behavior from pandas API on Spark since pandas API on Spark follows the behavior of pandas, not SQL.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n/databricks/python/lib/python3.10/site-packages/pyspark/pandas/utils.py:1026: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `to_table`, the existing index is lost when converting to table.\n  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    " import pandas as pd\n",
    " import pyspark.pandas as ps\n",
    " from sklearn.datasets import load_iris\n",
    "\n",
    " # Load the IRIS dataset\n",
    " iris = load_iris()\n",
    "\n",
    " # Create a DataFrame\n",
    " iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    " iris_df.rename(columns={\n",
    "     'sepal length (cm)': 'sepal_length',\n",
    "     'sepal width (cm)': 'sepal_width',\n",
    "     'petal length (cm)': 'petal_length',\n",
    "     'petal width (cm)': 'petal_width'\n",
    " }, inplace=True)\n",
    "\n",
    "iris_df['species'] = iris.target.astype(str)\n",
    "\n",
    " # Convert to Spark DataFrame and write to Unity Catalog\n",
    " ps.from_pandas(iris_df).to_table(\"marcin_demo.demo_schema_v2.sample_iris_v2\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7471522-eded-4504-b24b-cd7434040a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>sepal_length</th><th>sepal_width</th><th>petal_length</th><th>petal_width</th><th>species</th></tr></thead><tbody><tr><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>0</td></tr><tr><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>5.4</td><td>3.9</td><td>1.7</td><td>0.4</td><td>0</td></tr><tr><td>4.6</td><td>3.4</td><td>1.4</td><td>0.3</td><td>0</td></tr><tr><td>5.0</td><td>3.4</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>4.4</td><td>2.9</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>4.9</td><td>3.1</td><td>1.5</td><td>0.1</td><td>0</td></tr><tr><td>5.4</td><td>3.7</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>4.8</td><td>3.4</td><td>1.6</td><td>0.2</td><td>0</td></tr><tr><td>4.8</td><td>3.0</td><td>1.4</td><td>0.1</td><td>0</td></tr><tr><td>4.3</td><td>3.0</td><td>1.1</td><td>0.1</td><td>0</td></tr><tr><td>5.8</td><td>4.0</td><td>1.2</td><td>0.2</td><td>0</td></tr><tr><td>5.7</td><td>4.4</td><td>1.5</td><td>0.4</td><td>0</td></tr><tr><td>5.4</td><td>3.9</td><td>1.3</td><td>0.4</td><td>0</td></tr><tr><td>5.1</td><td>3.5</td><td>1.4</td><td>0.3</td><td>0</td></tr><tr><td>5.7</td><td>3.8</td><td>1.7</td><td>0.3</td><td>0</td></tr><tr><td>5.1</td><td>3.8</td><td>1.5</td><td>0.3</td><td>0</td></tr><tr><td>5.4</td><td>3.4</td><td>1.7</td><td>0.2</td><td>0</td></tr><tr><td>5.1</td><td>3.7</td><td>1.5</td><td>0.4</td><td>0</td></tr><tr><td>4.6</td><td>3.6</td><td>1.0</td><td>0.2</td><td>0</td></tr><tr><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>0</td></tr><tr><td>4.8</td><td>3.4</td><td>1.9</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.0</td><td>1.6</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.4</td><td>1.6</td><td>0.4</td><td>0</td></tr><tr><td>5.2</td><td>3.5</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>5.2</td><td>3.4</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>4.7</td><td>3.2</td><td>1.6</td><td>0.2</td><td>0</td></tr><tr><td>4.8</td><td>3.1</td><td>1.6</td><td>0.2</td><td>0</td></tr><tr><td>5.4</td><td>3.4</td><td>1.5</td><td>0.4</td><td>0</td></tr><tr><td>5.2</td><td>4.1</td><td>1.5</td><td>0.1</td><td>0</td></tr><tr><td>5.5</td><td>4.2</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>4.9</td><td>3.1</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.2</td><td>1.2</td><td>0.2</td><td>0</td></tr><tr><td>5.5</td><td>3.5</td><td>1.3</td><td>0.2</td><td>0</td></tr><tr><td>4.9</td><td>3.6</td><td>1.4</td><td>0.1</td><td>0</td></tr><tr><td>4.4</td><td>3.0</td><td>1.3</td><td>0.2</td><td>0</td></tr><tr><td>5.1</td><td>3.4</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.5</td><td>1.3</td><td>0.3</td><td>0</td></tr><tr><td>4.5</td><td>2.3</td><td>1.3</td><td>0.3</td><td>0</td></tr><tr><td>4.4</td><td>3.2</td><td>1.3</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.5</td><td>1.6</td><td>0.6</td><td>0</td></tr><tr><td>5.1</td><td>3.8</td><td>1.9</td><td>0.4</td><td>0</td></tr><tr><td>4.8</td><td>3.0</td><td>1.4</td><td>0.3</td><td>0</td></tr><tr><td>5.1</td><td>3.8</td><td>1.6</td><td>0.2</td><td>0</td></tr><tr><td>4.6</td><td>3.2</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>5.3</td><td>3.7</td><td>1.5</td><td>0.2</td><td>0</td></tr><tr><td>5.0</td><td>3.3</td><td>1.4</td><td>0.2</td><td>0</td></tr><tr><td>7.0</td><td>3.2</td><td>4.7</td><td>1.4</td><td>1</td></tr><tr><td>6.4</td><td>3.2</td><td>4.5</td><td>1.5</td><td>1</td></tr><tr><td>6.9</td><td>3.1</td><td>4.9</td><td>1.5</td><td>1</td></tr><tr><td>5.5</td><td>2.3</td><td>4.0</td><td>1.3</td><td>1</td></tr><tr><td>6.5</td><td>2.8</td><td>4.6</td><td>1.5</td><td>1</td></tr><tr><td>5.7</td><td>2.8</td><td>4.5</td><td>1.3</td><td>1</td></tr><tr><td>6.3</td><td>3.3</td><td>4.7</td><td>1.6</td><td>1</td></tr><tr><td>4.9</td><td>2.4</td><td>3.3</td><td>1.0</td><td>1</td></tr><tr><td>6.6</td><td>2.9</td><td>4.6</td><td>1.3</td><td>1</td></tr><tr><td>5.2</td><td>2.7</td><td>3.9</td><td>1.4</td><td>1</td></tr><tr><td>5.0</td><td>2.0</td><td>3.5</td><td>1.0</td><td>1</td></tr><tr><td>5.9</td><td>3.0</td><td>4.2</td><td>1.5</td><td>1</td></tr><tr><td>6.0</td><td>2.2</td><td>4.0</td><td>1.0</td><td>1</td></tr><tr><td>6.1</td><td>2.9</td><td>4.7</td><td>1.4</td><td>1</td></tr><tr><td>5.6</td><td>2.9</td><td>3.6</td><td>1.3</td><td>1</td></tr><tr><td>6.7</td><td>3.1</td><td>4.4</td><td>1.4</td><td>1</td></tr><tr><td>5.6</td><td>3.0</td><td>4.5</td><td>1.5</td><td>1</td></tr><tr><td>5.8</td><td>2.7</td><td>4.1</td><td>1.0</td><td>1</td></tr><tr><td>6.2</td><td>2.2</td><td>4.5</td><td>1.5</td><td>1</td></tr><tr><td>5.6</td><td>2.5</td><td>3.9</td><td>1.1</td><td>1</td></tr><tr><td>5.9</td><td>3.2</td><td>4.8</td><td>1.8</td><td>1</td></tr><tr><td>6.1</td><td>2.8</td><td>4.0</td><td>1.3</td><td>1</td></tr><tr><td>6.3</td><td>2.5</td><td>4.9</td><td>1.5</td><td>1</td></tr><tr><td>6.1</td><td>2.8</td><td>4.7</td><td>1.2</td><td>1</td></tr><tr><td>6.4</td><td>2.9</td><td>4.3</td><td>1.3</td><td>1</td></tr><tr><td>6.6</td><td>3.0</td><td>4.4</td><td>1.4</td><td>1</td></tr><tr><td>6.8</td><td>2.8</td><td>4.8</td><td>1.4</td><td>1</td></tr><tr><td>6.7</td><td>3.0</td><td>5.0</td><td>1.7</td><td>1</td></tr><tr><td>6.0</td><td>2.9</td><td>4.5</td><td>1.5</td><td>1</td></tr><tr><td>5.7</td><td>2.6</td><td>3.5</td><td>1.0</td><td>1</td></tr><tr><td>5.5</td><td>2.4</td><td>3.8</td><td>1.1</td><td>1</td></tr><tr><td>5.5</td><td>2.4</td><td>3.7</td><td>1.0</td><td>1</td></tr><tr><td>5.8</td><td>2.7</td><td>3.9</td><td>1.2</td><td>1</td></tr><tr><td>6.0</td><td>2.7</td><td>5.1</td><td>1.6</td><td>1</td></tr><tr><td>5.4</td><td>3.0</td><td>4.5</td><td>1.5</td><td>1</td></tr><tr><td>6.0</td><td>3.4</td><td>4.5</td><td>1.6</td><td>1</td></tr><tr><td>6.7</td><td>3.1</td><td>4.7</td><td>1.5</td><td>1</td></tr><tr><td>6.3</td><td>2.3</td><td>4.4</td><td>1.3</td><td>1</td></tr><tr><td>5.6</td><td>3.0</td><td>4.1</td><td>1.3</td><td>1</td></tr><tr><td>5.5</td><td>2.5</td><td>4.0</td><td>1.3</td><td>1</td></tr><tr><td>5.5</td><td>2.6</td><td>4.4</td><td>1.2</td><td>1</td></tr><tr><td>6.1</td><td>3.0</td><td>4.6</td><td>1.4</td><td>1</td></tr><tr><td>5.8</td><td>2.6</td><td>4.0</td><td>1.2</td><td>1</td></tr><tr><td>5.0</td><td>2.3</td><td>3.3</td><td>1.0</td><td>1</td></tr><tr><td>5.6</td><td>2.7</td><td>4.2</td><td>1.3</td><td>1</td></tr><tr><td>5.7</td><td>3.0</td><td>4.2</td><td>1.2</td><td>1</td></tr><tr><td>5.7</td><td>2.9</td><td>4.2</td><td>1.3</td><td>1</td></tr><tr><td>6.2</td><td>2.9</td><td>4.3</td><td>1.3</td><td>1</td></tr><tr><td>5.1</td><td>2.5</td><td>3.0</td><td>1.1</td><td>1</td></tr><tr><td>5.7</td><td>2.8</td><td>4.1</td><td>1.3</td><td>1</td></tr><tr><td>6.3</td><td>3.3</td><td>6.0</td><td>2.5</td><td>2</td></tr><tr><td>5.8</td><td>2.7</td><td>5.1</td><td>1.9</td><td>2</td></tr><tr><td>7.1</td><td>3.0</td><td>5.9</td><td>2.1</td><td>2</td></tr><tr><td>6.3</td><td>2.9</td><td>5.6</td><td>1.8</td><td>2</td></tr><tr><td>6.5</td><td>3.0</td><td>5.8</td><td>2.2</td><td>2</td></tr><tr><td>7.6</td><td>3.0</td><td>6.6</td><td>2.1</td><td>2</td></tr><tr><td>4.9</td><td>2.5</td><td>4.5</td><td>1.7</td><td>2</td></tr><tr><td>7.3</td><td>2.9</td><td>6.3</td><td>1.8</td><td>2</td></tr><tr><td>6.7</td><td>2.5</td><td>5.8</td><td>1.8</td><td>2</td></tr><tr><td>7.2</td><td>3.6</td><td>6.1</td><td>2.5</td><td>2</td></tr><tr><td>6.5</td><td>3.2</td><td>5.1</td><td>2.0</td><td>2</td></tr><tr><td>6.4</td><td>2.7</td><td>5.3</td><td>1.9</td><td>2</td></tr><tr><td>6.8</td><td>3.0</td><td>5.5</td><td>2.1</td><td>2</td></tr><tr><td>5.7</td><td>2.5</td><td>5.0</td><td>2.0</td><td>2</td></tr><tr><td>5.8</td><td>2.8</td><td>5.1</td><td>2.4</td><td>2</td></tr><tr><td>6.4</td><td>3.2</td><td>5.3</td><td>2.3</td><td>2</td></tr><tr><td>6.5</td><td>3.0</td><td>5.5</td><td>1.8</td><td>2</td></tr><tr><td>7.7</td><td>3.8</td><td>6.7</td><td>2.2</td><td>2</td></tr><tr><td>7.7</td><td>2.6</td><td>6.9</td><td>2.3</td><td>2</td></tr><tr><td>6.0</td><td>2.2</td><td>5.0</td><td>1.5</td><td>2</td></tr><tr><td>6.9</td><td>3.2</td><td>5.7</td><td>2.3</td><td>2</td></tr><tr><td>5.6</td><td>2.8</td><td>4.9</td><td>2.0</td><td>2</td></tr><tr><td>7.7</td><td>2.8</td><td>6.7</td><td>2.0</td><td>2</td></tr><tr><td>6.3</td><td>2.7</td><td>4.9</td><td>1.8</td><td>2</td></tr><tr><td>6.7</td><td>3.3</td><td>5.7</td><td>2.1</td><td>2</td></tr><tr><td>7.2</td><td>3.2</td><td>6.0</td><td>1.8</td><td>2</td></tr><tr><td>6.2</td><td>2.8</td><td>4.8</td><td>1.8</td><td>2</td></tr><tr><td>6.1</td><td>3.0</td><td>4.9</td><td>1.8</td><td>2</td></tr><tr><td>6.4</td><td>2.8</td><td>5.6</td><td>2.1</td><td>2</td></tr><tr><td>7.2</td><td>3.0</td><td>5.8</td><td>1.6</td><td>2</td></tr><tr><td>7.4</td><td>2.8</td><td>6.1</td><td>1.9</td><td>2</td></tr><tr><td>7.9</td><td>3.8</td><td>6.4</td><td>2.0</td><td>2</td></tr><tr><td>6.4</td><td>2.8</td><td>5.6</td><td>2.2</td><td>2</td></tr><tr><td>6.3</td><td>2.8</td><td>5.1</td><td>1.5</td><td>2</td></tr><tr><td>6.1</td><td>2.6</td><td>5.6</td><td>1.4</td><td>2</td></tr><tr><td>7.7</td><td>3.0</td><td>6.1</td><td>2.3</td><td>2</td></tr><tr><td>6.3</td><td>3.4</td><td>5.6</td><td>2.4</td><td>2</td></tr><tr><td>6.4</td><td>3.1</td><td>5.5</td><td>1.8</td><td>2</td></tr><tr><td>6.0</td><td>3.0</td><td>4.8</td><td>1.8</td><td>2</td></tr><tr><td>6.9</td><td>3.1</td><td>5.4</td><td>2.1</td><td>2</td></tr><tr><td>6.7</td><td>3.1</td><td>5.6</td><td>2.4</td><td>2</td></tr><tr><td>6.9</td><td>3.1</td><td>5.1</td><td>2.3</td><td>2</td></tr><tr><td>5.8</td><td>2.7</td><td>5.1</td><td>1.9</td><td>2</td></tr><tr><td>6.8</td><td>3.2</td><td>5.9</td><td>2.3</td><td>2</td></tr><tr><td>6.7</td><td>3.3</td><td>5.7</td><td>2.5</td><td>2</td></tr><tr><td>6.7</td><td>3.0</td><td>5.2</td><td>2.3</td><td>2</td></tr><tr><td>6.3</td><td>2.5</td><td>5.0</td><td>1.9</td><td>2</td></tr><tr><td>6.5</td><td>3.0</td><td>5.2</td><td>2.0</td><td>2</td></tr><tr><td>6.2</td><td>3.4</td><td>5.4</td><td>2.3</td><td>2</td></tr><tr><td>5.9</td><td>3.0</td><td>5.1</td><td>1.8</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         5.1,
         3.5,
         1.4,
         0.2,
         "0"
        ],
        [
         4.9,
         3.0,
         1.4,
         0.2,
         "0"
        ],
        [
         4.7,
         3.2,
         1.3,
         0.2,
         "0"
        ],
        [
         4.6,
         3.1,
         1.5,
         0.2,
         "0"
        ],
        [
         5.0,
         3.6,
         1.4,
         0.2,
         "0"
        ],
        [
         5.4,
         3.9,
         1.7,
         0.4,
         "0"
        ],
        [
         4.6,
         3.4,
         1.4,
         0.3,
         "0"
        ],
        [
         5.0,
         3.4,
         1.5,
         0.2,
         "0"
        ],
        [
         4.4,
         2.9,
         1.4,
         0.2,
         "0"
        ],
        [
         4.9,
         3.1,
         1.5,
         0.1,
         "0"
        ],
        [
         5.4,
         3.7,
         1.5,
         0.2,
         "0"
        ],
        [
         4.8,
         3.4,
         1.6,
         0.2,
         "0"
        ],
        [
         4.8,
         3.0,
         1.4,
         0.1,
         "0"
        ],
        [
         4.3,
         3.0,
         1.1,
         0.1,
         "0"
        ],
        [
         5.8,
         4.0,
         1.2,
         0.2,
         "0"
        ],
        [
         5.7,
         4.4,
         1.5,
         0.4,
         "0"
        ],
        [
         5.4,
         3.9,
         1.3,
         0.4,
         "0"
        ],
        [
         5.1,
         3.5,
         1.4,
         0.3,
         "0"
        ],
        [
         5.7,
         3.8,
         1.7,
         0.3,
         "0"
        ],
        [
         5.1,
         3.8,
         1.5,
         0.3,
         "0"
        ],
        [
         5.4,
         3.4,
         1.7,
         0.2,
         "0"
        ],
        [
         5.1,
         3.7,
         1.5,
         0.4,
         "0"
        ],
        [
         4.6,
         3.6,
         1.0,
         0.2,
         "0"
        ],
        [
         5.1,
         3.3,
         1.7,
         0.5,
         "0"
        ],
        [
         4.8,
         3.4,
         1.9,
         0.2,
         "0"
        ],
        [
         5.0,
         3.0,
         1.6,
         0.2,
         "0"
        ],
        [
         5.0,
         3.4,
         1.6,
         0.4,
         "0"
        ],
        [
         5.2,
         3.5,
         1.5,
         0.2,
         "0"
        ],
        [
         5.2,
         3.4,
         1.4,
         0.2,
         "0"
        ],
        [
         4.7,
         3.2,
         1.6,
         0.2,
         "0"
        ],
        [
         4.8,
         3.1,
         1.6,
         0.2,
         "0"
        ],
        [
         5.4,
         3.4,
         1.5,
         0.4,
         "0"
        ],
        [
         5.2,
         4.1,
         1.5,
         0.1,
         "0"
        ],
        [
         5.5,
         4.2,
         1.4,
         0.2,
         "0"
        ],
        [
         4.9,
         3.1,
         1.5,
         0.2,
         "0"
        ],
        [
         5.0,
         3.2,
         1.2,
         0.2,
         "0"
        ],
        [
         5.5,
         3.5,
         1.3,
         0.2,
         "0"
        ],
        [
         4.9,
         3.6,
         1.4,
         0.1,
         "0"
        ],
        [
         4.4,
         3.0,
         1.3,
         0.2,
         "0"
        ],
        [
         5.1,
         3.4,
         1.5,
         0.2,
         "0"
        ],
        [
         5.0,
         3.5,
         1.3,
         0.3,
         "0"
        ],
        [
         4.5,
         2.3,
         1.3,
         0.3,
         "0"
        ],
        [
         4.4,
         3.2,
         1.3,
         0.2,
         "0"
        ],
        [
         5.0,
         3.5,
         1.6,
         0.6,
         "0"
        ],
        [
         5.1,
         3.8,
         1.9,
         0.4,
         "0"
        ],
        [
         4.8,
         3.0,
         1.4,
         0.3,
         "0"
        ],
        [
         5.1,
         3.8,
         1.6,
         0.2,
         "0"
        ],
        [
         4.6,
         3.2,
         1.4,
         0.2,
         "0"
        ],
        [
         5.3,
         3.7,
         1.5,
         0.2,
         "0"
        ],
        [
         5.0,
         3.3,
         1.4,
         0.2,
         "0"
        ],
        [
         7.0,
         3.2,
         4.7,
         1.4,
         "1"
        ],
        [
         6.4,
         3.2,
         4.5,
         1.5,
         "1"
        ],
        [
         6.9,
         3.1,
         4.9,
         1.5,
         "1"
        ],
        [
         5.5,
         2.3,
         4.0,
         1.3,
         "1"
        ],
        [
         6.5,
         2.8,
         4.6,
         1.5,
         "1"
        ],
        [
         5.7,
         2.8,
         4.5,
         1.3,
         "1"
        ],
        [
         6.3,
         3.3,
         4.7,
         1.6,
         "1"
        ],
        [
         4.9,
         2.4,
         3.3,
         1.0,
         "1"
        ],
        [
         6.6,
         2.9,
         4.6,
         1.3,
         "1"
        ],
        [
         5.2,
         2.7,
         3.9,
         1.4,
         "1"
        ],
        [
         5.0,
         2.0,
         3.5,
         1.0,
         "1"
        ],
        [
         5.9,
         3.0,
         4.2,
         1.5,
         "1"
        ],
        [
         6.0,
         2.2,
         4.0,
         1.0,
         "1"
        ],
        [
         6.1,
         2.9,
         4.7,
         1.4,
         "1"
        ],
        [
         5.6,
         2.9,
         3.6,
         1.3,
         "1"
        ],
        [
         6.7,
         3.1,
         4.4,
         1.4,
         "1"
        ],
        [
         5.6,
         3.0,
         4.5,
         1.5,
         "1"
        ],
        [
         5.8,
         2.7,
         4.1,
         1.0,
         "1"
        ],
        [
         6.2,
         2.2,
         4.5,
         1.5,
         "1"
        ],
        [
         5.6,
         2.5,
         3.9,
         1.1,
         "1"
        ],
        [
         5.9,
         3.2,
         4.8,
         1.8,
         "1"
        ],
        [
         6.1,
         2.8,
         4.0,
         1.3,
         "1"
        ],
        [
         6.3,
         2.5,
         4.9,
         1.5,
         "1"
        ],
        [
         6.1,
         2.8,
         4.7,
         1.2,
         "1"
        ],
        [
         6.4,
         2.9,
         4.3,
         1.3,
         "1"
        ],
        [
         6.6,
         3.0,
         4.4,
         1.4,
         "1"
        ],
        [
         6.8,
         2.8,
         4.8,
         1.4,
         "1"
        ],
        [
         6.7,
         3.0,
         5.0,
         1.7,
         "1"
        ],
        [
         6.0,
         2.9,
         4.5,
         1.5,
         "1"
        ],
        [
         5.7,
         2.6,
         3.5,
         1.0,
         "1"
        ],
        [
         5.5,
         2.4,
         3.8,
         1.1,
         "1"
        ],
        [
         5.5,
         2.4,
         3.7,
         1.0,
         "1"
        ],
        [
         5.8,
         2.7,
         3.9,
         1.2,
         "1"
        ],
        [
         6.0,
         2.7,
         5.1,
         1.6,
         "1"
        ],
        [
         5.4,
         3.0,
         4.5,
         1.5,
         "1"
        ],
        [
         6.0,
         3.4,
         4.5,
         1.6,
         "1"
        ],
        [
         6.7,
         3.1,
         4.7,
         1.5,
         "1"
        ],
        [
         6.3,
         2.3,
         4.4,
         1.3,
         "1"
        ],
        [
         5.6,
         3.0,
         4.1,
         1.3,
         "1"
        ],
        [
         5.5,
         2.5,
         4.0,
         1.3,
         "1"
        ],
        [
         5.5,
         2.6,
         4.4,
         1.2,
         "1"
        ],
        [
         6.1,
         3.0,
         4.6,
         1.4,
         "1"
        ],
        [
         5.8,
         2.6,
         4.0,
         1.2,
         "1"
        ],
        [
         5.0,
         2.3,
         3.3,
         1.0,
         "1"
        ],
        [
         5.6,
         2.7,
         4.2,
         1.3,
         "1"
        ],
        [
         5.7,
         3.0,
         4.2,
         1.2,
         "1"
        ],
        [
         5.7,
         2.9,
         4.2,
         1.3,
         "1"
        ],
        [
         6.2,
         2.9,
         4.3,
         1.3,
         "1"
        ],
        [
         5.1,
         2.5,
         3.0,
         1.1,
         "1"
        ],
        [
         5.7,
         2.8,
         4.1,
         1.3,
         "1"
        ],
        [
         6.3,
         3.3,
         6.0,
         2.5,
         "2"
        ],
        [
         5.8,
         2.7,
         5.1,
         1.9,
         "2"
        ],
        [
         7.1,
         3.0,
         5.9,
         2.1,
         "2"
        ],
        [
         6.3,
         2.9,
         5.6,
         1.8,
         "2"
        ],
        [
         6.5,
         3.0,
         5.8,
         2.2,
         "2"
        ],
        [
         7.6,
         3.0,
         6.6,
         2.1,
         "2"
        ],
        [
         4.9,
         2.5,
         4.5,
         1.7,
         "2"
        ],
        [
         7.3,
         2.9,
         6.3,
         1.8,
         "2"
        ],
        [
         6.7,
         2.5,
         5.8,
         1.8,
         "2"
        ],
        [
         7.2,
         3.6,
         6.1,
         2.5,
         "2"
        ],
        [
         6.5,
         3.2,
         5.1,
         2.0,
         "2"
        ],
        [
         6.4,
         2.7,
         5.3,
         1.9,
         "2"
        ],
        [
         6.8,
         3.0,
         5.5,
         2.1,
         "2"
        ],
        [
         5.7,
         2.5,
         5.0,
         2.0,
         "2"
        ],
        [
         5.8,
         2.8,
         5.1,
         2.4,
         "2"
        ],
        [
         6.4,
         3.2,
         5.3,
         2.3,
         "2"
        ],
        [
         6.5,
         3.0,
         5.5,
         1.8,
         "2"
        ],
        [
         7.7,
         3.8,
         6.7,
         2.2,
         "2"
        ],
        [
         7.7,
         2.6,
         6.9,
         2.3,
         "2"
        ],
        [
         6.0,
         2.2,
         5.0,
         1.5,
         "2"
        ],
        [
         6.9,
         3.2,
         5.7,
         2.3,
         "2"
        ],
        [
         5.6,
         2.8,
         4.9,
         2.0,
         "2"
        ],
        [
         7.7,
         2.8,
         6.7,
         2.0,
         "2"
        ],
        [
         6.3,
         2.7,
         4.9,
         1.8,
         "2"
        ],
        [
         6.7,
         3.3,
         5.7,
         2.1,
         "2"
        ],
        [
         7.2,
         3.2,
         6.0,
         1.8,
         "2"
        ],
        [
         6.2,
         2.8,
         4.8,
         1.8,
         "2"
        ],
        [
         6.1,
         3.0,
         4.9,
         1.8,
         "2"
        ],
        [
         6.4,
         2.8,
         5.6,
         2.1,
         "2"
        ],
        [
         7.2,
         3.0,
         5.8,
         1.6,
         "2"
        ],
        [
         7.4,
         2.8,
         6.1,
         1.9,
         "2"
        ],
        [
         7.9,
         3.8,
         6.4,
         2.0,
         "2"
        ],
        [
         6.4,
         2.8,
         5.6,
         2.2,
         "2"
        ],
        [
         6.3,
         2.8,
         5.1,
         1.5,
         "2"
        ],
        [
         6.1,
         2.6,
         5.6,
         1.4,
         "2"
        ],
        [
         7.7,
         3.0,
         6.1,
         2.3,
         "2"
        ],
        [
         6.3,
         3.4,
         5.6,
         2.4,
         "2"
        ],
        [
         6.4,
         3.1,
         5.5,
         1.8,
         "2"
        ],
        [
         6.0,
         3.0,
         4.8,
         1.8,
         "2"
        ],
        [
         6.9,
         3.1,
         5.4,
         2.1,
         "2"
        ],
        [
         6.7,
         3.1,
         5.6,
         2.4,
         "2"
        ],
        [
         6.9,
         3.1,
         5.1,
         2.3,
         "2"
        ],
        [
         5.8,
         2.7,
         5.1,
         1.9,
         "2"
        ],
        [
         6.8,
         3.2,
         5.9,
         2.3,
         "2"
        ],
        [
         6.7,
         3.3,
         5.7,
         2.5,
         "2"
        ],
        [
         6.7,
         3.0,
         5.2,
         2.3,
         "2"
        ],
        [
         6.3,
         2.5,
         5.0,
         1.9,
         "2"
        ],
        [
         6.5,
         3.0,
         5.2,
         2.0,
         "2"
        ],
        [
         6.2,
         3.4,
         5.4,
         2.3,
         "2"
        ],
        [
         5.9,
         3.0,
         5.1,
         1.8,
         "2"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "sepal_length",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "sepal_width",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "petal_length",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "petal_width",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "species",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trigger a search query\n",
    "display(spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1af83bf9-26df-4669-b0f0-bae70cb6e153",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 0. View System Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ca411d-971c-440c-a8b7-5d09a008681a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COLUMN LINEAGE TABLE SCHEMA ===\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>account_id</td><td>string</td><td>The id of the Databricks account.</td></tr><tr><td>metastore_id</td><td>string</td><td>The id of the Unity Catalog metastore.</td></tr><tr><td>workspace_id</td><td>string</td><td>The id of the workspace</td></tr><tr><td>entity_type</td><td>string</td><td>The type of entity the lineage transaction was captured from. The supported value is NOTEBOOK, JOB, PIPELINE, DASHBOARD_V3 (AI/BI Dashboard), DBSQL_DASHBOARD (Legacy dashboard), DBSQL_QUERY, OR NULL.</td></tr><tr><td>entity_id</td><td>string</td><td>The id of the entity the lineage transaction was captured from. If entity_type is NULL, entity_id is NULL.</td></tr><tr><td>entity_run_id</td><td>string</td><td>id to describe the unique run of the entity, or NULL. This differs for each entity type:\n",
       "\n",
       "Notebook: command_run_id\n",
       "\n",
       "Job: job_run_id\n",
       "\n",
       "Databricks SQL query: statement_id\n",
       "\n",
       "Dashboard: statement_id\n",
       "\n",
       "Legacy dashboard: statement_id\n",
       "\n",
       "Pipeline: pipeline_update_id\n",
       "\n",
       "If entity_type is NULL, entity_run_id is NULL. Records with statement_id and job_run_id can be joined with the query history and jobs system tables respectively.</td></tr><tr><td>source_table_full_name</td><td>string</td><td>Three-level name to identify the source table.</td></tr><tr><td>source_table_catalog</td><td>string</td><td>The catalog of the source table.</td></tr><tr><td>source_table_schema</td><td>string</td><td>The schema of the source table.</td></tr><tr><td>source_table_name</td><td>string</td><td>The name of the source table.</td></tr><tr><td>source_path</td><td>string</td><td>Location in cloud storage of the source table, or the path if it’s reading from cloud storage directly.</td></tr><tr><td>source_type</td><td>string</td><td>The type of the source. The value is TABLE, PATH, VIEW, or STREAMING_TABLE.</td></tr><tr><td>source_column_name</td><td>string</td><td>The name of the source column.</td></tr><tr><td>target_table_full_name</td><td>string</td><td>Three-level name to identify the target table.</td></tr><tr><td>target_table_catalog</td><td>string</td><td>The catalog of the target table.</td></tr><tr><td>target_table_schema</td><td>string</td><td>The schema of the target table.</td></tr><tr><td>target_table_name</td><td>string</td><td>The name of the target table.</td></tr><tr><td>target_path</td><td>string</td><td>Location in cloud storage of the target table.</td></tr><tr><td>target_type</td><td>string</td><td>The type of the target. The value is TABLE, PATH, VIEW,or STREAMING TABLE.</td></tr><tr><td>target_column_name</td><td>string</td><td>The name of the target column.</td></tr><tr><td>created_by</td><td>string</td><td>The user who generated this lineage. This can be a Databricks username, a Databricks service principal ID, “System-User”, or NULL if the user information cannot be captured.</td></tr><tr><td>event_time</td><td>timestamp</td><td>The timestamp when the lineage was generated. Timezone information is recorded at the end of the value with +00:00 representing UTC.</td></tr><tr><td>event_date</td><td>date</td><td>The date when the lineage was generated. This is a partitioned column.</td></tr><tr><td>record_id</td><td>string</td><td>Primary key of each row, it is auto-generated and cannot be joined with any tables</td></tr><tr><td>event_id</td><td>string</td><td>One query or one spark job run could append multiple lineage rows, this event_id is a unique id to group the rows that belong to the same event. This is generated in the pipeline and cannot be joined with any tables.</td></tr><tr><td>statement_id</td><td>string</td><td>A foreign key to join with query history system table. It is set when a query is from a warehouse or serverless warehouse.</td></tr><tr><td>entity_metadata</td><td>struct<job_info:struct<job_id:string,job_run_id:string>,dashboard_id:string,legacy_dashboard_id:string,notebook_id:string,sql_query_id:string,dlt_pipeline_info:struct<dlt_pipeline_id:string,dlt_update_id:string>></td><td>It is a list of ids of the query context which is joinable with other system tables.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "account_id",
         "string",
         "The id of the Databricks account."
        ],
        [
         "metastore_id",
         "string",
         "The id of the Unity Catalog metastore."
        ],
        [
         "workspace_id",
         "string",
         "The id of the workspace"
        ],
        [
         "entity_type",
         "string",
         "The type of entity the lineage transaction was captured from. The supported value is NOTEBOOK, JOB, PIPELINE, DASHBOARD_V3 (AI/BI Dashboard), DBSQL_DASHBOARD (Legacy dashboard), DBSQL_QUERY, OR NULL."
        ],
        [
         "entity_id",
         "string",
         "The id of the entity the lineage transaction was captured from. If entity_type is NULL, entity_id is NULL."
        ],
        [
         "entity_run_id",
         "string",
         "id to describe the unique run of the entity, or NULL. This differs for each entity type:\n\nNotebook: command_run_id\n\nJob: job_run_id\n\nDatabricks SQL query: statement_id\n\nDashboard: statement_id\n\nLegacy dashboard: statement_id\n\nPipeline: pipeline_update_id\n\nIf entity_type is NULL, entity_run_id is NULL. Records with statement_id and job_run_id can be joined with the query history and jobs system tables respectively."
        ],
        [
         "source_table_full_name",
         "string",
         "Three-level name to identify the source table."
        ],
        [
         "source_table_catalog",
         "string",
         "The catalog of the source table."
        ],
        [
         "source_table_schema",
         "string",
         "The schema of the source table."
        ],
        [
         "source_table_name",
         "string",
         "The name of the source table."
        ],
        [
         "source_path",
         "string",
         "Location in cloud storage of the source table, or the path if it’s reading from cloud storage directly."
        ],
        [
         "source_type",
         "string",
         "The type of the source. The value is TABLE, PATH, VIEW, or STREAMING_TABLE."
        ],
        [
         "source_column_name",
         "string",
         "The name of the source column."
        ],
        [
         "target_table_full_name",
         "string",
         "Three-level name to identify the target table."
        ],
        [
         "target_table_catalog",
         "string",
         "The catalog of the target table."
        ],
        [
         "target_table_schema",
         "string",
         "The schema of the target table."
        ],
        [
         "target_table_name",
         "string",
         "The name of the target table."
        ],
        [
         "target_path",
         "string",
         "Location in cloud storage of the target table."
        ],
        [
         "target_type",
         "string",
         "The type of the target. The value is TABLE, PATH, VIEW,or STREAMING TABLE."
        ],
        [
         "target_column_name",
         "string",
         "The name of the target column."
        ],
        [
         "created_by",
         "string",
         "The user who generated this lineage. This can be a Databricks username, a Databricks service principal ID, “System-User”, or NULL if the user information cannot be captured."
        ],
        [
         "event_time",
         "timestamp",
         "The timestamp when the lineage was generated. Timezone information is recorded at the end of the value with +00:00 representing UTC."
        ],
        [
         "event_date",
         "date",
         "The date when the lineage was generated. This is a partitioned column."
        ],
        [
         "record_id",
         "string",
         "Primary key of each row, it is auto-generated and cannot be joined with any tables"
        ],
        [
         "event_id",
         "string",
         "One query or one spark job run could append multiple lineage rows, this event_id is a unique id to group the rows that belong to the same event. This is generated in the pipeline and cannot be joined with any tables."
        ],
        [
         "statement_id",
         "string",
         "A foreign key to join with query history system table. It is set when a query is from a warehouse or serverless warehouse."
        ],
        [
         "entity_metadata",
         "struct<job_info:struct<job_id:string,job_run_id:string>,dashboard_id:string,legacy_dashboard_id:string,notebook_id:string,sql_query_id:string,dlt_pipeline_info:struct<dlt_pipeline_id:string,dlt_update_id:string>>",
         "It is a list of ids of the query context which is joinable with other system tables."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check what columns exist in column_lineage\n",
    "print(\"=== COLUMN LINEAGE TABLE SCHEMA ===\")\n",
    "display(spark.sql(\"DESCRIBE system.access.column_lineage\").limit(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "051be523-42ec-4550-96cb-1a1960f6d861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n=== QUERY HISTORY TABLE SCHEMA ===\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>account_id</td><td>string</td><td>ID of the account.</td></tr><tr><td>workspace_id</td><td>string</td><td>The ID of the workspace where the query was run.</td></tr><tr><td>statement_id</td><td>string</td><td>The ID that uniquely identifies the execution of the statement. You can use this ID to find the statement execution in the Query History UI.</td></tr><tr><td>executed_by</td><td>string</td><td>The email address or username of the user who ran the statement.</td></tr><tr><td>session_id</td><td>string</td><td>The Spark session ID.</td></tr><tr><td>execution_status</td><td>string</td><td>The statement termination state. Possible values are:\n",
       "\n",
       "FINISHED: execution was successful\n",
       "\n",
       "FAILED: execution failed with the reason for failure described in the accompanying error message\n",
       "\n",
       "CANCELED: execution was canceled</td></tr><tr><td>compute</td><td>struct<type:string,cluster_id:string,warehouse_id:string></td><td>A struct that represents the type of compute resource used to run the statement and the ID of the resource where applicable. The type value will be WAREHOUSE.</td></tr><tr><td>executed_by_user_id</td><td>string</td><td>The ID of the user who ran the statement.</td></tr><tr><td>statement_text</td><td>string</td><td>Text of the SQL statement. If you have configured customer-managed keys, statement_text is empty.</td></tr><tr><td>statement_type</td><td>string</td><td>The statement type. For example: ALTER, COPY, and`INSERT`.</td></tr><tr><td>error_message</td><td>string</td><td>Message describing the error condition. If you have configured customer-managed keys, error_message is empty.</td></tr><tr><td>client_application</td><td>string</td><td>Client application that ran the statement. For example: Databricks SQL, Tableau, and Power BI.</td></tr><tr><td>client_driver</td><td>string</td><td>The connector used to connect to Databricks to run the statement. For example: Databricks SQL Driver for Go, Databricks ODBC Driver, Databricks JDBC Driver.</td></tr><tr><td>total_duration_ms</td><td>bigint</td><td>Total execution time of the statement in milliseconds ( excluding result fetch time ).</td></tr><tr><td>waiting_for_compute_duration_ms</td><td>bigint</td><td>Time spent waiting for compute resources to be provisioned in milliseconds.</td></tr><tr><td>waiting_at_capacity_duration_ms</td><td>bigint</td><td>Time spent waiting in queue for available compute capacity in milliseconds.</td></tr><tr><td>execution_duration_ms</td><td>bigint</td><td>Time spent executing the statement in milliseconds.</td></tr><tr><td>compilation_duration_ms</td><td>bigint</td><td>Time spent loading metadata and optimizing the statement in milliseconds.</td></tr><tr><td>total_task_duration_ms</td><td>bigint</td><td>The sum of all task durations in milliseconds. This time represents the combined time it took to run the query across all cores of all nodes. It can be significantly longer than the wall-clock duration if multiple tasks are executed in parallel. It can be shorter than the wall-clock duration if tasks wait for available nodes.</td></tr><tr><td>result_fetch_duration_ms</td><td>bigint</td><td>Time spent, in milliseconds, fetching the statement results after the execution finished.</td></tr><tr><td>start_time</td><td>timestamp</td><td>The time when Databricks received the request. Timezone information is recorded at the end of the value with +00:00 representing UTC.</td></tr><tr><td>end_time</td><td>timestamp</td><td>The time the statement execution ended, excluding result fetch time. Timezone information is recorded at the end of the value with +00:00 representing UTC.</td></tr><tr><td>update_time</td><td>timestamp</td><td>The time the statement last received a progress update. Timezone information is recorded at the end of the value with +00:00 representing UTC.</td></tr><tr><td>read_partitions</td><td>bigint</td><td>The number of partitions read after pruning.</td></tr><tr><td>pruned_files</td><td>bigint</td><td>The number of pruned files.</td></tr><tr><td>read_files</td><td>bigint</td><td>The number of files read after pruning.</td></tr><tr><td>read_rows</td><td>bigint</td><td>Total number of rows read by the statement.</td></tr><tr><td>produced_rows</td><td>bigint</td><td>Total number of rows returned by the statement.</td></tr><tr><td>read_bytes</td><td>bigint</td><td>Total size of data read by the statement in bytes.</td></tr><tr><td>read_io_cache_percent</td><td>tinyint</td><td>The percentage of bytes of persistent data read from the IO cache.</td></tr><tr><td>from_result_cache</td><td>boolean</td><td>TRUE indicates that the statement result was fetched from the cache.</td></tr><tr><td>spilled_local_bytes</td><td>bigint</td><td>Size of data, in bytes, temporarily written to disk while executing the statement.</td></tr><tr><td>written_bytes</td><td>bigint</td><td>The size in bytes of persistent data written to cloud object storage.</td></tr><tr><td>shuffle_read_bytes</td><td>bigint</td><td>The total amount of data in bytes sent over the network.</td></tr><tr><td>query_source</td><td>struct<job_info:struct<job_id:string,job_run_id:string,job_task_run_id:string>,legacy_dashboard_id:string,dashboard_id:string,alert_id:string,notebook_id:string,sql_query_id:string,genie_space_id:string></td><td>A struct that contains key-value pairs representing one or more Databricks entities that were involved in the execution of this statement, such as jobs, notebooks, or dashboards. This field only records Databricks entities and are not sorted by execution order. Statement executions that contain multiple IDs indicate that the execution was triggered by multiple entities: for example, an Alert may trigger on a Job result and call a SQL Query, so all three IDs will be populated within query_source.</td></tr><tr><td>executed_as_user_id</td><td>string</td><td>The ID of the user or service principal whose privilege was used to run the statement.</td></tr><tr><td>executed_as</td><td>string</td><td>The name of the user or service principal whose privilege was used to run the statement.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "account_id",
         "string",
         "ID of the account."
        ],
        [
         "workspace_id",
         "string",
         "The ID of the workspace where the query was run."
        ],
        [
         "statement_id",
         "string",
         "The ID that uniquely identifies the execution of the statement. You can use this ID to find the statement execution in the Query History UI."
        ],
        [
         "executed_by",
         "string",
         "The email address or username of the user who ran the statement."
        ],
        [
         "session_id",
         "string",
         "The Spark session ID."
        ],
        [
         "execution_status",
         "string",
         "The statement termination state. Possible values are:\n\nFINISHED: execution was successful\n\nFAILED: execution failed with the reason for failure described in the accompanying error message\n\nCANCELED: execution was canceled"
        ],
        [
         "compute",
         "struct<type:string,cluster_id:string,warehouse_id:string>",
         "A struct that represents the type of compute resource used to run the statement and the ID of the resource where applicable. The type value will be WAREHOUSE."
        ],
        [
         "executed_by_user_id",
         "string",
         "The ID of the user who ran the statement."
        ],
        [
         "statement_text",
         "string",
         "Text of the SQL statement. If you have configured customer-managed keys, statement_text is empty."
        ],
        [
         "statement_type",
         "string",
         "The statement type. For example: ALTER, COPY, and`INSERT`."
        ],
        [
         "error_message",
         "string",
         "Message describing the error condition. If you have configured customer-managed keys, error_message is empty."
        ],
        [
         "client_application",
         "string",
         "Client application that ran the statement. For example: Databricks SQL, Tableau, and Power BI."
        ],
        [
         "client_driver",
         "string",
         "The connector used to connect to Databricks to run the statement. For example: Databricks SQL Driver for Go, Databricks ODBC Driver, Databricks JDBC Driver."
        ],
        [
         "total_duration_ms",
         "bigint",
         "Total execution time of the statement in milliseconds ( excluding result fetch time )."
        ],
        [
         "waiting_for_compute_duration_ms",
         "bigint",
         "Time spent waiting for compute resources to be provisioned in milliseconds."
        ],
        [
         "waiting_at_capacity_duration_ms",
         "bigint",
         "Time spent waiting in queue for available compute capacity in milliseconds."
        ],
        [
         "execution_duration_ms",
         "bigint",
         "Time spent executing the statement in milliseconds."
        ],
        [
         "compilation_duration_ms",
         "bigint",
         "Time spent loading metadata and optimizing the statement in milliseconds."
        ],
        [
         "total_task_duration_ms",
         "bigint",
         "The sum of all task durations in milliseconds. This time represents the combined time it took to run the query across all cores of all nodes. It can be significantly longer than the wall-clock duration if multiple tasks are executed in parallel. It can be shorter than the wall-clock duration if tasks wait for available nodes."
        ],
        [
         "result_fetch_duration_ms",
         "bigint",
         "Time spent, in milliseconds, fetching the statement results after the execution finished."
        ],
        [
         "start_time",
         "timestamp",
         "The time when Databricks received the request. Timezone information is recorded at the end of the value with +00:00 representing UTC."
        ],
        [
         "end_time",
         "timestamp",
         "The time the statement execution ended, excluding result fetch time. Timezone information is recorded at the end of the value with +00:00 representing UTC."
        ],
        [
         "update_time",
         "timestamp",
         "The time the statement last received a progress update. Timezone information is recorded at the end of the value with +00:00 representing UTC."
        ],
        [
         "read_partitions",
         "bigint",
         "The number of partitions read after pruning."
        ],
        [
         "pruned_files",
         "bigint",
         "The number of pruned files."
        ],
        [
         "read_files",
         "bigint",
         "The number of files read after pruning."
        ],
        [
         "read_rows",
         "bigint",
         "Total number of rows read by the statement."
        ],
        [
         "produced_rows",
         "bigint",
         "Total number of rows returned by the statement."
        ],
        [
         "read_bytes",
         "bigint",
         "Total size of data read by the statement in bytes."
        ],
        [
         "read_io_cache_percent",
         "tinyint",
         "The percentage of bytes of persistent data read from the IO cache."
        ],
        [
         "from_result_cache",
         "boolean",
         "TRUE indicates that the statement result was fetched from the cache."
        ],
        [
         "spilled_local_bytes",
         "bigint",
         "Size of data, in bytes, temporarily written to disk while executing the statement."
        ],
        [
         "written_bytes",
         "bigint",
         "The size in bytes of persistent data written to cloud object storage."
        ],
        [
         "shuffle_read_bytes",
         "bigint",
         "The total amount of data in bytes sent over the network."
        ],
        [
         "query_source",
         "struct<job_info:struct<job_id:string,job_run_id:string,job_task_run_id:string>,legacy_dashboard_id:string,dashboard_id:string,alert_id:string,notebook_id:string,sql_query_id:string,genie_space_id:string>",
         "A struct that contains key-value pairs representing one or more Databricks entities that were involved in the execution of this statement, such as jobs, notebooks, or dashboards. This field only records Databricks entities and are not sorted by execution order. Statement executions that contain multiple IDs indicate that the execution was triggered by multiple entities: for example, an Alert may trigger on a Job result and call a SQL Query, so all three IDs will be populated within query_source."
        ],
        [
         "executed_as_user_id",
         "string",
         "The ID of the user or service principal whose privilege was used to run the statement."
        ],
        [
         "executed_as",
         "string",
         "The name of the user or service principal whose privilege was used to run the statement."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check what columns exist in query_history\n",
    "print(\"\\n=== QUERY HISTORY TABLE SCHEMA ===\")\n",
    "display(spark.sql(\"DESCRIBE system.query.history\").limit(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "613392ed-6229-4607-ba99-33115d1d8f47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Sample Column Lineage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4492154-30ea-4b61-a3fd-701e2ee02b46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample column lineage data:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>statement_id</th><th>source_table_full_name</th><th>source_column_name</th><th>target_table_full_name</th><th>target_column_name</th><th>entity_type</th></tr></thead><tbody><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>sepal_length</td><td>null</td><td>null</td><td>NOTEBOOK</td></tr><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_length</td><td>null</td><td>null</td><td>NOTEBOOK</td></tr><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>null</td><td>null</td><td>NOTEBOOK</td></tr><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>sepal_width</td><td>null</td><td>null</td><td>NOTEBOOK</td></tr><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>null</td><td>null</td><td>NOTEBOOK</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "sepal_length",
         null,
         null,
         "NOTEBOOK"
        ],
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_length",
         null,
         null,
         "NOTEBOOK"
        ],
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         null,
         null,
         "NOTEBOOK"
        ],
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "sepal_width",
         null,
         null,
         "NOTEBOOK"
        ],
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         null,
         null,
         "NOTEBOOK"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\": \"A foreign key to join with query history system table. It is set when a query is from a warehouse or serverless warehouse.\"}",
         "name": "statement_id",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"Three-level name to identify the source table.\"}",
         "name": "source_table_full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The name of the source column.\"}",
         "name": "source_column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"Three-level name to identify the target table.\"}",
         "name": "target_table_full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The name of the target column.\"}",
         "name": "target_column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The type of entity the lineage transaction was captured from. The supported value is NOTEBOOK, JOB, PIPELINE, DASHBOARD_V3 (AI/BI Dashboard), DBSQL_DASHBOARD (Legacy dashboard), DBSQL_QUERY, OR NULL.\"}",
         "name": "entity_type",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Sample column lineage data:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  statement_id,\n",
    "  source_table_full_name,\n",
    "  source_column_name,\n",
    "  target_table_full_name,\n",
    "  target_column_name,\n",
    "  entity_type\n",
    "FROM system.access.column_lineage\n",
    "WHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
    "LIMIT 5\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bca040f1-53ea-4a72-930d-1f723fd4ad55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Sample Query History Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0d00e4-d745-4047-a738-cc5ca00740a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample queries by marcin.jimenez@databricks.com:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>statement_id</th><th>executed_by</th><th>start_time</th><th>workspace_id</th><th>query_source</th><th>statement_text</th></tr></thead><tbody><tr><td>7d2fccbb-51ca-4572-8e23-57b5096d95a7</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:41:36.207Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  source_table_full_name,\n",
       "  source_column_name,\n",
       "  target_table_full_name,\n",
       "  target_column_name\n",
       "FROM system.access.column_lineage\n",
       "WHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
       "LIMIT 5\n",
       "\"\"\"))</td></tr><tr><td>555929ad-e540-42c3-86b2-af058c8163ab</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:40:41.790Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  executed_by,\n",
       "  start_time,\n",
       "  workspace_id,\n",
       "  query_source,\n",
       "  statement_text\n",
       "FROM system.query.history\n",
       "WHERE executed_by = '{CURRENT_USER}'\n",
       "  AND start_time >= '{START_TIME.isoformat()}'\n",
       "ORDER BY start_time DESC\n",
       "LIMIT 50\n",
       "\"\"\"))</td></tr><tr><td>66dd3b59-3ebd-4695-9273-80a4ca2f3dec</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:40:27.706Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  executed_by,\n",
       "  start_time,\n",
       "  workspace_id,\n",
       "  query_source,\n",
       "  statement_text\n",
       "FROM system.query.history\n",
       "WHERE executed_by = '{CURRENT_USER}'\n",
       "  AND start_time >= '{START_TIME.isoformat()}'\n",
       "ORDER BY start_time DESC\n",
       "LIMIT 5\n",
       "\"\"\"))</td></tr><tr><td>55b01942-8993-4e27-9007-636d5aabfb90</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:39:53.455Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  executed_by,\n",
       "  start_time,\n",
       "  workspace_id,\n",
       "  query_source\n",
       "FROM system.query.history\n",
       "WHERE executed_by = '{CURRENT_USER}'\n",
       "  AND start_time >= '{START_TIME.isoformat()}'\n",
       "ORDER BY start_time DESC\n",
       "LIMIT 5\n",
       "\"\"\"))</td></tr><tr><td>249830ea-6ea9-4c64-bc62-8f5d295b92e3</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:39:31.512Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  executed_by,\n",
       "  start_time,\n",
       "  workspace_id,\n",
       "  query_source\n",
       "FROM system.query.history\n",
       "WHERE executed_by = '{CURRENT_USER}'\n",
       "  AND start_time >= '{START_TIME.isoformat()}'\n",
       "ORDER BY start_time DESC\n",
       "LIMIT 5\n",
       "\"\"\").show(truncate=False)</td></tr><tr><td>d914a8e8-72e7-4aab-bf8c-3d0524058b58</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:38:42.033Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  source_table_full_name,\n",
       "  source_column_name,\n",
       "  target_table_full_name,\n",
       "  target_column_name\n",
       "FROM system.access.column_lineage\n",
       "WHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
       "LIMIT 5\n",
       "\"\"\"))</td></tr><tr><td>b72921d9-171a-434c-bbd1-876cd5a05bf4</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:38:33.083Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\"))</td></tr><tr><td>6370f434-db6f-436e-a3f0-44eedb20ff43</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:38:20.646Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\"))</td></tr><tr><td>d70908ad-c8b9-4b65-b26e-75b64c5a9494</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:36:26.941Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>CURRENT_USER = spark.sql(\"SELECT current_user()\").collect()[0][0]</td></tr><tr><td>577ae8e6-0095-400e-ab3c-4228eda1f498</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:36:05.892Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  source_table_full_name,\n",
       "  source_column_name,\n",
       "  target_table_full_name,\n",
       "  target_column_name\n",
       "FROM system.access.column_lineage\n",
       "WHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
       "LIMIT 5\n",
       "\"\"\"))</td></tr><tr><td>5d55dbba-5bff-4d51-9a49-5bb5bb54eba7</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:48.757Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\").limit(50))</td></tr><tr><td>8ab81467-63e2-4b01-a23b-d2aa9313e8a1</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:48.361Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\").limit(50))</td></tr><tr><td>3b7ea8ae-6127-4d64-8b95-adb9a04f1ef3</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:40.678Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\"))</td></tr><tr><td>be2667ff-c52f-4f7a-95fa-eba5538da40a</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:40.240Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\"))</td></tr><tr><td>fe943c5b-7b60-4416-bba9-c0d5b53fb721</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:25.668Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False))</td></tr><tr><td>0d996340-00e2-43e9-adfe-8d3a0fd600c1</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:25.434Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False))</td></tr><tr><td>8e4ae034-28b8-49d8-9778-9bda11827ff8</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:19.530Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.query.history\").limit(50))</td></tr><tr><td>02021537-f487-4a69-be0a-13321ddf8e49</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:19.125Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>display(spark.sql(\"DESCRIBE system.query.history\").limit(50))</td></tr><tr><td>d778383b-2b5d-45fd-9944-87dbe9c33ae2</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:35:02.905Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(f\"\"\"\n",
       "SELECT \n",
       "  statement_id,\n",
       "  source_table_full_name,\n",
       "  source_column_name,\n",
       "  target_table_full_name,\n",
       "  target_column_name\n",
       "FROM system.access.column_lineage\n",
       "WHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
       "LIMIT 5\n",
       "\"\"\").show(truncate=False)</td></tr><tr><td>0b74a7ed-2a61-48c7-8b53-113ca4d55b02</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:34:39.758Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(\"DESCRIBE system.query.history\").show(50, truncate=False)</td></tr><tr><td>10b6bd0d-ad74-46c0-9e18-4c3c4ee3c076</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:34:39.279Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(\"DESCRIBE system.query.history\").show(50, truncate=False)</td></tr><tr><td>a5c02d80-0eb3-4f42-bbf7-cc5aa403b5c3</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:34:38.558Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False)</td></tr><tr><td>ce65f94a-b094-48ff-8e2f-3594b60c6ebb</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:34:38.009Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False)</td></tr><tr><td>30fcb976-477a-4ac4-b8a8-5e4d6855a317</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:34:13.658Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\").show()</td></tr><tr><td>fbd35ff1-e4f5-4bd0-8a5e-4a9c0cd61804</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:52.679Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>self._psdf.spark.frame(index_col=index_col).write.saveAsTable(\n",
       "    name=name, format=format, mode=mode, partitionBy=partition_cols, **options\n",
       ")</td></tr><tr><td>2be51134-5100-40c6-a97e-5ef922105861</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:47.584Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>SET TAG ON COLUMN sample_iris_v2.species SENSITIVE</td></tr><tr><td>6ddb6a3d-5768-4b59-9530-9ebcd06c23b2</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:47.075Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>-- -- 2) Tag the sensitive columns\n",
       "SET TAG ON COLUMN sample_iris_v2.petal_width SENSITIVE</td></tr><tr><td>f37ccf78-71ad-4d82-b1bb-6afdeeca55e8</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:45.127Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>-- 1) Create the table from the CSV in DBFS\n",
       "CREATE TABLE IF NOT EXISTS sample_iris_v2 (\n",
       "  sepal_length DOUBLE,\n",
       "  sepal_width  DOUBLE,\n",
       "  petal_length DOUBLE,\n",
       "  petal_width  DOUBLE,\n",
       "  species      STRING\n",
       ")\n",
       "USING DELTA</td></tr><tr><td>cb4e1f83-bb45-4cfe-ac45-5d1e7750d9e9</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:44.016Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>DROP TABLE IF EXISTS sample_iris_v2</td></tr><tr><td>e0ab8c94-73a8-4f97-9519-8970d88ad72b</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:43.213Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>USE marcin_demo.demo_schema_v2</td></tr><tr><td>fc82f15d-91b6-493d-9132-83f6c51517b0</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:42.678Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>CREATE SCHEMA IF NOT EXISTS demo_schema_v2</td></tr><tr><td>6d6e9b36-1ee3-4b68-a4fc-157946635c5d</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:42.159Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>USE CATALOG marcin_demo</td></tr><tr><td>b1ec1e96-1a75-4ea5-9b2c-2d5d8f8179f2</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:29.257Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>self._psdf.spark.frame(index_col=index_col).write.saveAsTable(\n",
       "    name=name, format=format, mode=mode, partitionBy=partition_cols, **options\n",
       ")</td></tr><tr><td>41875911-6784-4b97-8c28-62e2b40a3fec</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:25.134Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>-- -- 2) Tag the sensitive columns\n",
       "SET TAG ON COLUMN sample_iris.petal_width SENSITIVE</td></tr><tr><td>e08b6dd5-323d-4082-b289-2f55ef173007</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:23.138Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>-- 1) Create the table from the CSV in DBFS\n",
       "CREATE TABLE IF NOT EXISTS sample_iris_v2 (\n",
       "  sepal_length DOUBLE,\n",
       "  sepal_width  DOUBLE,\n",
       "  petal_length DOUBLE,\n",
       "  petal_width  DOUBLE,\n",
       "  species      STRING\n",
       ")\n",
       "USING DELTA</td></tr><tr><td>55ae80c1-f79e-497f-826e-bfa5d52c3104</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:22.554Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>DROP TABLE IF EXISTS sample_iris_v2</td></tr><tr><td>95a34485-5f84-41af-958a-ed16a5701b02</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:22.057Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>USE marcin_demo.demo_schema_v2</td></tr><tr><td>cc0fedb4-047f-4a38-a082-5aee6b437a77</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:21.393Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>CREATE SCHEMA IF NOT EXISTS demo_schema_v2</td></tr><tr><td>cf3c1a0d-8373-4f7c-a00b-57ca80c9d105</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:20.821Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>USE CATALOG marcin_demo</td></tr><tr><td>07539a7e-78b1-4ad3-9cf9-406007041fed</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:32:19.225Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>CURRENT_USER = spark.sql(\"SELECT current_user()\").collect()[0][0]</td></tr><tr><td>243ca019-0929-4f56-b681-77e70db0db19</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:28:11.426Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>result.groupBy(\"user_name\").agg(\n",
       "    count(\"*\").alias(\"access_count\"),\n",
       "    countDistinct(\"column_name\").alias(\"unique_columns\")\n",
       ").orderBy(\"access_count\", ascending=False).show()</td></tr><tr><td>81b4799f-02b5-42c8-99bb-de816e452b50</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:27:51.576Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>if result.count() > 0:</td></tr><tr><td>5b6eb7b6-3822-4525-adf7-5273135f0412</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:25:44.912Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>result.show(20, truncate=False)</td></tr><tr><td>71074375-b5bc-4d2a-8c04-c8274e98c44c</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:22:16.512Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>describe detail `query`.`history`</td></tr><tr><td>f8536f08-ef8a-4938-a643-fa429dea6ee7</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:22:11.683Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>result.show(20, truncate=False)</td></tr><tr><td>c5f57fe3-baff-4616-82f9-660fd1fb4be4</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:21:56.701Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>if result.count() > 0:</td></tr><tr><td>05f72b9c-11c2-4aff-ad15-3b9907bcb6ac</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:20:21.018Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>result.show(20, truncate=False)</td></tr><tr><td>05fce6f8-456a-46f4-a2fb-0c29467d0dc7</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:20:04.485Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>if result.count() > 0:</td></tr><tr><td>a8f5a289-448f-4591-a148-ad12376b9399</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:19:45.093Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>print(f\"\\nTotal sensitive columns: {sensitive_df.count()}\")</td></tr><tr><td>a73b7c9d-fc57-4b12-85c1-dfcfadfe34a8</td><td>marcin.jimenez@databricks.com</td><td>2025-07-23T00:19:44.463Z</td><td>984752964297111</td><td>List(List(null, null, null), null, null, null, 3650006914012235, null, null)</td><td>sensitive_df.show(truncate=False)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "7d2fccbb-51ca-4572-8e23-57b5096d95a7",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:41:36.207Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  source_table_full_name,\n  source_column_name,\n  target_table_full_name,\n  target_column_name\nFROM system.access.column_lineage\nWHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\nLIMIT 5\n\"\"\"))"
        ],
        [
         "555929ad-e540-42c3-86b2-af058c8163ab",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:40:41.790Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  executed_by,\n  start_time,\n  workspace_id,\n  query_source,\n  statement_text\nFROM system.query.history\nWHERE executed_by = '{CURRENT_USER}'\n  AND start_time >= '{START_TIME.isoformat()}'\nORDER BY start_time DESC\nLIMIT 50\n\"\"\"))"
        ],
        [
         "66dd3b59-3ebd-4695-9273-80a4ca2f3dec",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:40:27.706Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  executed_by,\n  start_time,\n  workspace_id,\n  query_source,\n  statement_text\nFROM system.query.history\nWHERE executed_by = '{CURRENT_USER}'\n  AND start_time >= '{START_TIME.isoformat()}'\nORDER BY start_time DESC\nLIMIT 5\n\"\"\"))"
        ],
        [
         "55b01942-8993-4e27-9007-636d5aabfb90",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:39:53.455Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  executed_by,\n  start_time,\n  workspace_id,\n  query_source\nFROM system.query.history\nWHERE executed_by = '{CURRENT_USER}'\n  AND start_time >= '{START_TIME.isoformat()}'\nORDER BY start_time DESC\nLIMIT 5\n\"\"\"))"
        ],
        [
         "249830ea-6ea9-4c64-bc62-8f5d295b92e3",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:39:31.512Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  executed_by,\n  start_time,\n  workspace_id,\n  query_source\nFROM system.query.history\nWHERE executed_by = '{CURRENT_USER}'\n  AND start_time >= '{START_TIME.isoformat()}'\nORDER BY start_time DESC\nLIMIT 5\n\"\"\").show(truncate=False)"
        ],
        [
         "d914a8e8-72e7-4aab-bf8c-3d0524058b58",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:38:42.033Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  source_table_full_name,\n  source_column_name,\n  target_table_full_name,\n  target_column_name\nFROM system.access.column_lineage\nWHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\nLIMIT 5\n\"\"\"))"
        ],
        [
         "b72921d9-171a-434c-bbd1-876cd5a05bf4",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:38:33.083Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\"))"
        ],
        [
         "6370f434-db6f-436e-a3f0-44eedb20ff43",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:38:20.646Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\"))"
        ],
        [
         "d70908ad-c8b9-4b65-b26e-75b64c5a9494",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:36:26.941Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "CURRENT_USER = spark.sql(\"SELECT current_user()\").collect()[0][0]"
        ],
        [
         "577ae8e6-0095-400e-ab3c-4228eda1f498",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:36:05.892Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  source_table_full_name,\n  source_column_name,\n  target_table_full_name,\n  target_column_name\nFROM system.access.column_lineage\nWHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\nLIMIT 5\n\"\"\"))"
        ],
        [
         "5d55dbba-5bff-4d51-9a49-5bb5bb54eba7",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:48.757Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\").limit(50))"
        ],
        [
         "8ab81467-63e2-4b01-a23b-d2aa9313e8a1",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:48.361Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\").limit(50))"
        ],
        [
         "3b7ea8ae-6127-4d64-8b95-adb9a04f1ef3",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:40.678Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\"))"
        ],
        [
         "be2667ff-c52f-4f7a-95fa-eba5538da40a",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:40.240Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\"))"
        ],
        [
         "fe943c5b-7b60-4416-bba9-c0d5b53fb721",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:25.668Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False))"
        ],
        [
         "0d996340-00e2-43e9-adfe-8d3a0fd600c1",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:25.434Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False))"
        ],
        [
         "8e4ae034-28b8-49d8-9778-9bda11827ff8",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:19.530Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.query.history\").limit(50))"
        ],
        [
         "02021537-f487-4a69-be0a-13321ddf8e49",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:19.125Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "display(spark.sql(\"DESCRIBE system.query.history\").limit(50))"
        ],
        [
         "d778383b-2b5d-45fd-9944-87dbe9c33ae2",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:35:02.905Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(f\"\"\"\nSELECT \n  statement_id,\n  source_table_full_name,\n  source_column_name,\n  target_table_full_name,\n  target_column_name\nFROM system.access.column_lineage\nWHERE source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\nLIMIT 5\n\"\"\").show(truncate=False)"
        ],
        [
         "0b74a7ed-2a61-48c7-8b53-113ca4d55b02",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:34:39.758Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(\"DESCRIBE system.query.history\").show(50, truncate=False)"
        ],
        [
         "10b6bd0d-ad74-46c0-9e18-4c3c4ee3c076",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:34:39.279Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(\"DESCRIBE system.query.history\").show(50, truncate=False)"
        ],
        [
         "a5c02d80-0eb3-4f42-bbf7-cc5aa403b5c3",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:34:38.558Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False)"
        ],
        [
         "ce65f94a-b094-48ff-8e2f-3594b60c6ebb",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:34:38.009Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(\"DESCRIBE system.access.column_lineage\").show(50, truncate=False)"
        ],
        [
         "30fcb976-477a-4ac4-b8a8-5e4d6855a317",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:34:13.658Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "spark.sql(f\"SELECT * FROM {TARGET_CATALOG}.{TARGET_SCHEMA}.sample_iris_v2\").show()"
        ],
        [
         "fbd35ff1-e4f5-4bd0-8a5e-4a9c0cd61804",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:52.679Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "self._psdf.spark.frame(index_col=index_col).write.saveAsTable(\n    name=name, format=format, mode=mode, partitionBy=partition_cols, **options\n)"
        ],
        [
         "2be51134-5100-40c6-a97e-5ef922105861",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:47.584Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "SET TAG ON COLUMN sample_iris_v2.species SENSITIVE"
        ],
        [
         "6ddb6a3d-5768-4b59-9530-9ebcd06c23b2",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:47.075Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "-- -- 2) Tag the sensitive columns\nSET TAG ON COLUMN sample_iris_v2.petal_width SENSITIVE"
        ],
        [
         "f37ccf78-71ad-4d82-b1bb-6afdeeca55e8",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:45.127Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "-- 1) Create the table from the CSV in DBFS\nCREATE TABLE IF NOT EXISTS sample_iris_v2 (\n  sepal_length DOUBLE,\n  sepal_width  DOUBLE,\n  petal_length DOUBLE,\n  petal_width  DOUBLE,\n  species      STRING\n)\nUSING DELTA"
        ],
        [
         "cb4e1f83-bb45-4cfe-ac45-5d1e7750d9e9",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:44.016Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "DROP TABLE IF EXISTS sample_iris_v2"
        ],
        [
         "e0ab8c94-73a8-4f97-9519-8970d88ad72b",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:43.213Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "USE marcin_demo.demo_schema_v2"
        ],
        [
         "fc82f15d-91b6-493d-9132-83f6c51517b0",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:42.678Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "CREATE SCHEMA IF NOT EXISTS demo_schema_v2"
        ],
        [
         "6d6e9b36-1ee3-4b68-a4fc-157946635c5d",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:42.159Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "USE CATALOG marcin_demo"
        ],
        [
         "b1ec1e96-1a75-4ea5-9b2c-2d5d8f8179f2",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:29.257Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "self._psdf.spark.frame(index_col=index_col).write.saveAsTable(\n    name=name, format=format, mode=mode, partitionBy=partition_cols, **options\n)"
        ],
        [
         "41875911-6784-4b97-8c28-62e2b40a3fec",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:25.134Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "-- -- 2) Tag the sensitive columns\nSET TAG ON COLUMN sample_iris.petal_width SENSITIVE"
        ],
        [
         "e08b6dd5-323d-4082-b289-2f55ef173007",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:23.138Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "-- 1) Create the table from the CSV in DBFS\nCREATE TABLE IF NOT EXISTS sample_iris_v2 (\n  sepal_length DOUBLE,\n  sepal_width  DOUBLE,\n  petal_length DOUBLE,\n  petal_width  DOUBLE,\n  species      STRING\n)\nUSING DELTA"
        ],
        [
         "55ae80c1-f79e-497f-826e-bfa5d52c3104",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:22.554Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "DROP TABLE IF EXISTS sample_iris_v2"
        ],
        [
         "95a34485-5f84-41af-958a-ed16a5701b02",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:22.057Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "USE marcin_demo.demo_schema_v2"
        ],
        [
         "cc0fedb4-047f-4a38-a082-5aee6b437a77",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:21.393Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "CREATE SCHEMA IF NOT EXISTS demo_schema_v2"
        ],
        [
         "cf3c1a0d-8373-4f7c-a00b-57ca80c9d105",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:20.821Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "USE CATALOG marcin_demo"
        ],
        [
         "07539a7e-78b1-4ad3-9cf9-406007041fed",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:32:19.225Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "CURRENT_USER = spark.sql(\"SELECT current_user()\").collect()[0][0]"
        ],
        [
         "243ca019-0929-4f56-b681-77e70db0db19",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:28:11.426Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "result.groupBy(\"user_name\").agg(\n    count(\"*\").alias(\"access_count\"),\n    countDistinct(\"column_name\").alias(\"unique_columns\")\n).orderBy(\"access_count\", ascending=False).show()"
        ],
        [
         "81b4799f-02b5-42c8-99bb-de816e452b50",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:27:51.576Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "if result.count() > 0:"
        ],
        [
         "5b6eb7b6-3822-4525-adf7-5273135f0412",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:25:44.912Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "result.show(20, truncate=False)"
        ],
        [
         "71074375-b5bc-4d2a-8c04-c8274e98c44c",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:22:16.512Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "describe detail `query`.`history`"
        ],
        [
         "f8536f08-ef8a-4938-a643-fa429dea6ee7",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:22:11.683Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "result.show(20, truncate=False)"
        ],
        [
         "c5f57fe3-baff-4616-82f9-660fd1fb4be4",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:21:56.701Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "if result.count() > 0:"
        ],
        [
         "05f72b9c-11c2-4aff-ad15-3b9907bcb6ac",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:20:21.018Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "result.show(20, truncate=False)"
        ],
        [
         "05fce6f8-456a-46f4-a2fb-0c29467d0dc7",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:20:04.485Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "if result.count() > 0:"
        ],
        [
         "a8f5a289-448f-4591-a148-ad12376b9399",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:19:45.093Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "print(f\"\\nTotal sensitive columns: {sensitive_df.count()}\")"
        ],
        [
         "a73b7c9d-fc57-4b12-85c1-dfcfadfe34a8",
         "marcin.jimenez@databricks.com",
         "2025-07-23T00:19:44.463Z",
         "984752964297111",
         [
          [
           null,
           null,
           null
          ],
          null,
          null,
          null,
          "3650006914012235",
          null,
          null
         ],
         "sensitive_df.show(truncate=False)"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\": \"The ID that uniquely identifies the execution of the statement. You can use this ID to find the statement execution in the Query History UI.\"}",
         "name": "statement_id",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The email address or username of the user who ran the statement.\"}",
         "name": "executed_by",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The time when Databricks received the request. Timezone information is recorded at the end of the value with +00:00 representing UTC.\"}",
         "name": "start_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{\"comment\": \"The ID of the workspace where the query was run.\"}",
         "name": "workspace_id",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"A struct that contains key-value pairs representing one or more Databricks entities that were involved in the execution of this statement, such as jobs, notebooks, or dashboards. This field only records Databricks entities and are not sorted by execution order. Statement executions that contain multiple IDs indicate that the execution was triggered by multiple entities: for example, an Alert may trigger on a Job result and call a SQL Query, so all three IDs will be populated within query_source.\"}",
         "name": "query_source",
         "type": "{\"fields\":[{\"metadata\":{},\"name\":\"job_info\",\"nullable\":true,\"type\":{\"fields\":[{\"metadata\":{},\"name\":\"job_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"job_run_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"job_task_run_id\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}},{\"metadata\":{},\"name\":\"legacy_dashboard_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"dashboard_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"alert_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"notebook_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"sql_query_id\",\"nullable\":true,\"type\":\"string\"},{\"metadata\":{},\"name\":\"genie_space_id\",\"nullable\":true,\"type\":\"string\"}],\"type\":\"struct\"}"
        },
        {
         "metadata": "{\"comment\": \"Text of the SQL statement. If you have configured customer-managed keys, statement_text is empty.\"}",
         "name": "statement_text",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Sample queries by {CURRENT_USER}:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  statement_id,\n",
    "  executed_by,\n",
    "  start_time,\n",
    "  workspace_id,\n",
    "  query_source,\n",
    "  statement_text\n",
    "FROM system.query.history\n",
    "WHERE executed_by = '{CURRENT_USER}'\n",
    "  AND start_time >= '{START_TIME.isoformat()}'\n",
    "ORDER BY start_time DESC\n",
    "LIMIT 50\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5eeb8626-185c-4813-9664-e9882343d91d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Simple Join - Show Column Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ca9c63-273a-4c89-9a2f-c43cde1a7553",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns accessed by marcin.jimenez@databricks.com:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>start_time</th><th>executed_by</th><th>source_table_full_name</th><th>source_column_name</th><th>target_table_full_name</th><th>target_column_name</th></tr></thead><tbody><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>null</td><td>null</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>sepal_width</td><td>null</td><td>null</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_length</td><td>null</td><td>null</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>null</td><td>null</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>sepal_length</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         null,
         null
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "sepal_width",
         null,
         null
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_length",
         null,
         null
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         null,
         null
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "sepal_length",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\": \"The time when Databricks received the request. Timezone information is recorded at the end of the value with +00:00 representing UTC.\"}",
         "name": "start_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{\"comment\": \"The email address or username of the user who ran the statement.\"}",
         "name": "executed_by",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"Three-level name to identify the source table.\"}",
         "name": "source_table_full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The name of the source column.\"}",
         "name": "source_column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"Three-level name to identify the target table.\"}",
         "name": "target_table_full_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The name of the target column.\"}",
         "name": "target_column_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join the tables on statement_id\n",
    "print(f\"Columns accessed by {CURRENT_USER}:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  qh.start_time,\n",
    "  qh.executed_by,\n",
    "  cl.source_table_full_name,\n",
    "  cl.source_column_name,\n",
    "  cl.target_table_full_name,\n",
    "  cl.target_column_name\n",
    "FROM system.query.history qh\n",
    "INNER JOIN system.access.column_lineage cl\n",
    "  ON qh.statement_id = cl.statement_id\n",
    "WHERE qh.executed_by = '{CURRENT_USER}'\n",
    "  AND qh.start_time >= '{START_TIME.isoformat()}'\n",
    "  AND cl.source_table_full_name LIKE '{TARGET_CATALOG}.{TARGET_SCHEMA}.%'\n",
    "ORDER BY qh.start_time DESC\n",
    "LIMIT 20\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a0513ca-d16d-436a-92f4-93613dd062e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Find Sensitive Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b89cd6b-3152-4356-8741-9180fea13558",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitive columns in our schema:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>table_name</th><th>column_name</th><th>tag_name</th><th>tag_value</th></tr></thead><tbody><tr><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>SENSITIVE</td><td></td></tr><tr><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>SENSITIVE</td><td></td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         "SENSITIVE",
         ""
        ],
        [
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         "SENSITIVE",
         ""
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "table_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tag_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tag_value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nTotal sensitive columns: 2\n"
     ]
    }
   ],
   "source": [
    "# List columns tagged as sensitive\n",
    "print(\"Sensitive columns in our schema:\")\n",
    "sensitive_df = spark.sql(f\"\"\"\n",
    "SELECT \n",
    "  CONCAT(catalog_name, '.', schema_name, '.', table_name) as table_name,\n",
    "  column_name,\n",
    "  tag_name,\n",
    "  tag_value\n",
    "FROM system.information_schema.column_tags\n",
    "WHERE catalog_name = '{TARGET_CATALOG}'\n",
    "  AND schema_name = '{TARGET_SCHEMA}'\n",
    "  AND tag_name IN ('PHI', 'PII', 'SENSITIVE', 'CONFIDENTIAL')\n",
    "ORDER BY table_name, column_name\n",
    "\"\"\")\n",
    "\n",
    "display(sensitive_df)\n",
    "print(f\"\\nTotal sensitive columns: {sensitive_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25b731b3-1741-4400-9fa8-3eb90d78b9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 5. Main Query - Who Accessed Sensitive Columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41a3f46d-5ebf-480e-9ec0-9d9655f29746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>access_time</th><th>user_name</th><th>table_name</th><th>column_name</th><th>access_type</th><th>tag_name</th></tr></thead><tbody><tr><td>2025-07-23T00:38:33.083Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr><tr><td>2025-07-23T00:38:33.083Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr><tr><td>2025-07-23T00:38:20.646Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr><tr><td>2025-07-23T00:38:20.646Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>petal_width</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr><tr><td>2025-07-23T00:34:13.658Z</td><td>marcin.jimenez@databricks.com</td><td>marcin_demo.demo_schema_v2.sample_iris_v2</td><td>species</td><td>NOTEBOOK</td><td>SENSITIVE</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-07-23T00:38:33.083Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         "NOTEBOOK",
         "SENSITIVE"
        ],
        [
         "2025-07-23T00:38:33.083Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         "NOTEBOOK",
         "SENSITIVE"
        ],
        [
         "2025-07-23T00:38:20.646Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         "NOTEBOOK",
         "SENSITIVE"
        ],
        [
         "2025-07-23T00:38:20.646Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         "NOTEBOOK",
         "SENSITIVE"
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "petal_width",
         "NOTEBOOK",
         "SENSITIVE"
        ],
        [
         "2025-07-23T00:34:13.658Z",
         "marcin.jimenez@databricks.com",
         "marcin_demo.demo_schema_v2.sample_iris_v2",
         "species",
         "NOTEBOOK",
         "SENSITIVE"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\": \"The time when Databricks received the request. Timezone information is recorded at the end of the value with +00:00 representing UTC.\"}",
         "name": "access_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{\"comment\": \"The email address or username of the user who ran the statement.\"}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"Three-level name to identify the source table.\"}",
         "name": "table_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The name of the source column.\"}",
         "name": "column_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\": \"The type of entity the lineage transaction was captured from. The supported value is NOTEBOOK, JOB, PIPELINE, DASHBOARD_V3 (AI/BI Dashboard), DBSQL_DASHBOARD (Legacy dashboard), DBSQL_QUERY, OR NULL.\"}",
         "name": "access_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tag_name",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Putting it all together\n",
    "result = spark.sql(f\"\"\"\n",
    "WITH sensitive_cols AS (\n",
    "  SELECT \n",
    "    CONCAT(catalog_name, '.', schema_name, '.', table_name) as table_name,\n",
    "    column_name,\n",
    "    tag_name\n",
    "  FROM system.information_schema.column_tags\n",
    "  WHERE catalog_name = '{TARGET_CATALOG}'\n",
    "    AND schema_name = '{TARGET_SCHEMA}'\n",
    "    AND tag_name IN ('PHI', 'PII', 'SENSITIVE')\n",
    ")\n",
    "SELECT \n",
    "  qh.start_time as access_time,\n",
    "  qh.executed_by as user_name,\n",
    "  cl.source_table_full_name as table_name,\n",
    "  cl.source_column_name as column_name,\n",
    "  cl.entity_type as access_type,\n",
    "  sc.tag_name\n",
    "FROM system.query.history qh\n",
    "INNER JOIN system.access.column_lineage cl\n",
    "  ON qh.statement_id = cl.statement_id\n",
    "INNER JOIN sensitive_cols sc\n",
    "  ON cl.source_table_full_name = sc.table_name\n",
    "  AND cl.source_column_name = sc.column_name\n",
    "WHERE qh.start_time >= '{START_TIME.isoformat()}'\n",
    "ORDER BY qh.start_time DESC\n",
    "LIMIT 100\n",
    "\"\"\")\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e381fa4-434b-441b-b4a0-506ddac22b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\uD83D\uDCCA SUMMARY BY USER:\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_name</th><th>access_count</th><th>unique_columns</th></tr></thead><tbody><tr><td>marcin.jimenez@databricks.com</td><td>6</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "marcin.jimenez@databricks.com",
         6,
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\": \"The email address or username of the user who ran the statement.\"}",
         "name": "user_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "access_count",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "unique_columns",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import count, countDistinct\n",
    "\n",
    "if result.count() > 0:    \n",
    "    print(\"\\n\uD83D\uDCCA SUMMARY BY USER:\")\n",
    "    display(result.groupBy(\"user_name\").agg(\n",
    "        count(\"*\").alias(\"access_count\"),\n",
    "        countDistinct(\"column_name\").alias(\"unique_columns\")\n",
    "    ).orderBy(\"access_count\", ascending=False))\n",
    "else:\n",
    "    print(\"✅ No sensitive column access detected in the specified time period.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8418158362754099,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "pii_phi_audit_simple_final",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}